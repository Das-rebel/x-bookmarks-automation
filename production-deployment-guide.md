# Production Deployment Guide: AI Bookmark Agent

## üéØ Overview

While ngrok is perfect for development and testing, production deployments require stable, scalable hosting solutions. This guide covers multiple deployment options for your AI Bookmark Agent.

## üèóÔ∏è Deployment Options

### 1. Heroku (Recommended for Beginners)
### 2. Vercel (Great for Serverless)
### 3. Railway (Modern Platform)
### 4. DigitalOcean App Platform
### 5. AWS/Azure/GCP (Enterprise)

---

## üöÄ Option 1: Heroku Deployment

### Prerequisites
- Heroku account (free tier available)
- Heroku CLI installed
- Git repository initialized

### Step 1: Prepare for Heroku

1. **Create `Procfile`:**
```bash
echo "web: node chatgpt-agent-server.js" > Procfile
```

2. **Update `package.json` with Heroku scripts:**
```json
{
  "scripts": {
    "start": "node chatgpt-agent-server.js",
    "heroku-postbuild": "echo 'Build complete'"
  },
  "engines": {
    "node": "18.x"
  }
}
```

3. **Create `.env.example`:**
```bash
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
OPENAI_API_KEY=your_openai_key
DEEPSEEK_API_KEY=your_deepseek_key
PORT=3001
```

### Step 2: Deploy to Heroku

```bash
# Login to Heroku
heroku login

# Create Heroku app
heroku create your-bookmark-agent

# Set environment variables
heroku config:set SUPABASE_URL=your_supabase_url
heroku config:set SUPABASE_KEY=your_supabase_key
heroku config:set OPENAI_API_KEY=your_openai_key
heroku config:set DEEPSEEK_API_KEY=your_deepseek_key

# Deploy
git add .
git commit -m "Deploy to Heroku"
git push heroku main
```

### Step 3: Update ChatGPT Schema

Replace ngrok URL with Heroku URL:
```json
"servers": [
  {
    "url": "https://your-bookmark-agent.herokuapp.com",
    "description": "Production AI Agent Server"
  }
]
```

### Step 4: Test Production Deployment

```bash
# Test health endpoint
curl https://your-bookmark-agent.herokuapp.com/health

# Test search endpoint
curl -X POST https://your-bookmark-agent.herokuapp.com/api/search-bookmarks \
  -H "Content-Type: application/json" \
  -d '{"search_query": "AI", "limit": 5}'
```

---

## ‚ö° Option 2: Vercel Deployment

### Step 1: Prepare for Vercel

1. **Create `vercel.json`:**
```json
{
  "version": 2,
  "builds": [
    {
      "src": "chatgpt-agent-server.js",
      "use": "@vercel/node"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "/chatgpt-agent-server.js"
    }
  ],
  "env": {
    "SUPABASE_URL": "@supabase_url",
    "SUPABASE_KEY": "@supabase_key",
    "OPENAI_API_KEY": "@openai_api_key",
    "DEEPSEEK_API_KEY": "@deepseek_api_key"
  }
}
```

2. **Modify server for Vercel compatibility:**
Add to `chatgpt-agent-server.js`:
```javascript
// Add this for Vercel compatibility
if (process.env.VERCEL) {
  module.exports = server.app;
}
```

### Step 2: Deploy to Vercel

```bash
# Install Vercel CLI
npm install -g vercel

# Login and deploy
vercel login
vercel

# Set environment variables
vercel env add SUPABASE_URL
vercel env add SUPABASE_KEY
vercel env add OPENAI_API_KEY
vercel env add DEEPSEEK_API_KEY

# Redeploy with environment variables
vercel --prod
```

### Step 3: Update ChatGPT Schema

```json
"servers": [
  {
    "url": "https://your-project.vercel.app",
    "description": "Production AI Agent Server"
  }
]
```

---

## üöÑ Option 3: Railway Deployment

### Step 1: Prepare for Railway

1. **Create `railway.json`:**
```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "node chatgpt-agent-server.js",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

### Step 2: Deploy to Railway

```bash
# Install Railway CLI
npm install -g @railway/cli

# Login and initialize
railway login
railway init

# Add environment variables
railway variables set SUPABASE_URL=your_supabase_url
railway variables set SUPABASE_KEY=your_supabase_key
railway variables set OPENAI_API_KEY=your_openai_key
railway variables set DEEPSEEK_API_KEY=your_deepseek_key

# Deploy
railway up
```

---

## üåä Option 4: DigitalOcean App Platform

### Step 1: Create App Spec

1. **Create `.do/app.yaml`:**
```yaml
name: ai-bookmark-agent
services:
- name: web
  source_dir: /
  github:
    repo: your-username/your-repo
    branch: main
  run_command: node chatgpt-agent-server.js
  environment_slug: node-js
  instance_count: 1
  instance_size_slug: basic-xxs
  envs:
  - key: SUPABASE_URL
    value: your_supabase_url
  - key: SUPABASE_KEY
    value: your_supabase_key
  - key: OPENAI_API_KEY
    value: your_openai_key
  - key: DEEPSEEK_API_KEY
    value: your_deepseek_key
  http_port: 3001
```

### Step 2: Deploy via DigitalOcean Console

1. Go to [DigitalOcean Apps](https://cloud.digitalocean.com/apps)
2. Click "Create App"
3. Connect your GitHub repository
4. Use the app spec configuration
5. Deploy and get your app URL

---

## ‚òÅÔ∏è Option 5: AWS/Azure/GCP

### AWS (Elastic Beanstalk)

1. **Install AWS CLI and EB CLI**
2. **Create `Dockerrun.aws.json`:**
```json
{
  "AWSEBDockerrunVersion": "1",
  "Image": {
    "Name": "node:18-alpine",
    "Update": "true"
  },
  "Ports": [
    {
      "ContainerPort": "3001"
    }
  ]
}
```

3. **Deploy:**
```bash
eb init
eb create production
eb deploy
```

### Azure (App Service)

```bash
# Install Azure CLI
az login

# Create resource group
az group create --name bookmark-agent-rg --location eastus

# Create app service plan
az appservice plan create --name bookmark-agent-plan --resource-group bookmark-agent-rg --sku B1

# Create web app
az webapp create --name your-bookmark-agent --plan bookmark-agent-plan --resource-group bookmark-agent-rg --runtime "node|18-lts"

# Deploy
az webapp deployment source config-zip --name your-bookmark-agent --resource-group bookmark-agent-rg --src deploy.zip
```

---

## üîí Production Security Considerations

### 1. Environment Variables
```bash
# Never commit these to git!
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_service_role_key  # Use service role for server
OPENAI_API_KEY=sk-your-openai-key
DEEPSEEK_API_KEY=your-deepseek-key
NODE_ENV=production
```

### 2. HTTPS Configuration
Most platforms provide HTTPS automatically, but verify:
- SSL certificate is valid
- HTTP redirects to HTTPS
- CORS headers are properly configured

### 3. Rate Limiting & Security
Update `chatgpt-agent-server.js` for production:
```javascript
// Enhanced rate limiting for production
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: process.env.NODE_ENV === 'production' ? 50 : 100,
  message: 'Too many requests from this IP'
});

// Additional security headers
app.use(helmet({
  contentSecurityPolicy: {
    directives: {
      defaultSrc: ["'self'"],
      connectSrc: ["'self'", "https://chat.openai.com", "https://chatgpt.com"]
    }
  }
}));
```

### 4. Monitoring & Logging
```javascript
// Add production logging
const winston = require('winston');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' })
  ]
});

if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: winston.format.simple()
  }));
}
```

---

## üöÄ Deployment Checklist

### Pre-Deployment
- [ ] Environment variables configured
- [ ] Database schema applied
- [ ] API keys tested and valid
- [ ] CORS headers configured
- [ ] Rate limiting configured
- [ ] Error handling implemented

### Deployment
- [ ] Code committed to repository
- [ ] Platform-specific configuration files created
- [ ] Environment variables set on platform
- [ ] Application deployed successfully
- [ ] Health endpoint responding

### Post-Deployment
- [ ] ChatGPT schema updated with production URL
- [ ] All API endpoints tested
- [ ] Performance monitoring enabled
- [ ] Backup and disaster recovery planned
- [ ] Custom domain configured (optional)

### Testing Production
```bash
# Test all endpoints
curl https://your-production-url.com/health
curl -X POST https://your-production-url.com/api/search-bookmarks \
  -H "Content-Type: application/json" \
  -d '{"search_query": "test", "limit": 1}'
```

---

## üìä Platform Comparison

| Platform | Pros | Cons | Cost |
|----------|------|------|------|
| **Heroku** | Easy setup, good documentation | Can be slow on free tier | Free tier available |
| **Vercel** | Excellent performance, easy CI/CD | Primarily for frontend | Free tier available |
| **Railway** | Modern interface, good DX | Newer platform | Free tier available |
| **DigitalOcean** | Predictable pricing, good docs | More complex setup | $5/month minimum |
| **AWS/Azure/GCP** | Enterprise features, scalable | Complex, learning curve | Pay-as-you-go |

---

## üîÑ Migration from ngrok

When ready to move from ngrok to production:

1. **Deploy to chosen platform**
2. **Test all endpoints work**
3. **Update ChatGPT schema with production URL**
4. **Test ChatGPT integration**
5. **Monitor for issues**
6. **Keep ngrok setup for future development**

---

## üÜò Production Support

### Monitoring Tools
- **Uptime monitoring**: UptimeRobot, StatusPage
- **Error tracking**: Sentry, LogRocket
- **Performance**: New Relic, DataDog

### Backup Strategy
- **Database**: Supabase handles this
- **Code**: Git repository
- **Configuration**: Document all environment variables

### Scaling Considerations
- Most platforms auto-scale
- Monitor response times and error rates
- Consider CDN for global users
- Database connection pooling for high traffic

---

## üéØ Success Criteria

Your production deployment is successful when:

- ‚úÖ ChatGPT Custom GPT works without ngrok
- ‚úÖ All API endpoints respond correctly
- ‚úÖ HTTPS is properly configured
- ‚úÖ Performance is acceptable (< 3 second responses)
- ‚úÖ Error handling works as expected
- ‚úÖ Monitoring and logging are in place

**Ready for production!** Your AI Bookmark Agent is now accessible to ChatGPT from anywhere in the world.